{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to /home/exam/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/exam/nltk_data...\n",
      "[nltk_data]    | Error downloading 'conll2007' from\n",
      "[nltk_data]    |     <https://raw.githubusercontent.com/nltk/nltk_data\n",
      "[nltk_data]    |     /gh-pages/packages/corpora/conll2007.zip>:\n",
      "[nltk_data]    |     <urlopen error [Errno 104] Connection reset by\n",
      "[nltk_data]    |     peer>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Pierre/NNP)\n",
      "  (ORGANIZATION Vinken/NNP)\n",
      "  ,/,\n",
      "  61/CD\n",
      "  years/NNS\n",
      "  old/JJ\n",
      "  ,/,\n",
      "  will/MD\n",
      "  join/VB\n",
      "  the/DT\n",
      "  board/NN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  nonexecutive/JJ\n",
      "  director/NN\n",
      "  Nov./NNP\n",
      "  29/CD\n",
      "  ./.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /home/exam/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "sent = nltk.corpus.treebank.tagged_sents()\n",
    "print(nltk.ne_chunk(sent[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/exam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/exam/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "raw_text=(\"Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language. Organizations today have large volumes of voice and text data from various communication channels like emails, text messages, social media newsfeeds, video, audio, and more. They use NLP software to automatically process this data, analyze the intent or sentiment in the message, and respond in real time to human communication.There are 470 illegal structures, including restaurants and cafes, \")\n",
    "raw_words= word_tokenize(raw_text)\n",
    "tags=pos_tag(raw_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Natural/JJ\n",
      "  language/NN\n",
      "  processing/NN\n",
      "  (/(\n",
      "  (NE NLP/NNP)\n",
      "  )/)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  machine/NN\n",
      "  learning/VBG\n",
      "  technology/NN\n",
      "  that/WDT\n",
      "  gives/VBZ\n",
      "  computers/NNS\n",
      "  the/DT\n",
      "  ability/NN\n",
      "  to/TO\n",
      "  interpret/VB\n",
      "  ,/,\n",
      "  manipulate/VB\n",
      "  ,/,\n",
      "  and/CC\n",
      "  comprehend/VBP\n",
      "  human/JJ\n",
      "  language/NN\n",
      "  ./.\n",
      "  Organizations/NNS\n",
      "  today/NN\n",
      "  have/VBP\n",
      "  large/JJ\n",
      "  volumes/NNS\n",
      "  of/IN\n",
      "  voice/NN\n",
      "  and/CC\n",
      "  text/NN\n",
      "  data/NNS\n",
      "  from/IN\n",
      "  various/JJ\n",
      "  communication/NN\n",
      "  channels/NNS\n",
      "  like/IN\n",
      "  emails/NNS\n",
      "  ,/,\n",
      "  text/NN\n",
      "  messages/NNS\n",
      "  ,/,\n",
      "  social/JJ\n",
      "  media/NNS\n",
      "  newsfeeds/NNS\n",
      "  ,/,\n",
      "  video/NN\n",
      "  ,/,\n",
      "  audio/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  more/JJR\n",
      "  ./.\n",
      "  They/PRP\n",
      "  use/VBP\n",
      "  (NE NLP/NNP)\n",
      "  software/NN\n",
      "  to/TO\n",
      "  automatically/RB\n",
      "  process/VB\n",
      "  this/DT\n",
      "  data/NN\n",
      "  ,/,\n",
      "  analyze/IN\n",
      "  the/DT\n",
      "  intent/NN\n",
      "  or/CC\n",
      "  sentiment/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  message/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  respond/NN\n",
      "  in/IN\n",
      "  real/JJ\n",
      "  time/NN\n",
      "  to/TO\n",
      "  human/VB\n",
      "  communication.There/EX\n",
      "  are/VBP\n",
      "  470/CD\n",
      "  illegal/JJ\n",
      "  structures/NNS\n",
      "  ,/,\n",
      "  including/VBG\n",
      "  restaurants/NNS\n",
      "  and/CC\n",
      "  cafes/NN\n",
      "  ,/,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/exam/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/exam/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "ne = nltk.ne_chunk(tags,binary=True)\n",
    "print(ne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'JJ', 'O'),\n",
       " ('language', 'NN', 'O'),\n",
       " ('processing', 'NN', 'O'),\n",
       " ('(', '(', 'O'),\n",
       " ('NLP', 'NNP', 'B-NE'),\n",
       " (')', ')', 'O'),\n",
       " ('is', 'VBZ', 'O'),\n",
       " ('a', 'DT', 'O'),\n",
       " ('machine', 'NN', 'O'),\n",
       " ('learning', 'VBG', 'O'),\n",
       " ('technology', 'NN', 'O'),\n",
       " ('that', 'WDT', 'O'),\n",
       " ('gives', 'VBZ', 'O'),\n",
       " ('computers', 'NNS', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('ability', 'NN', 'O'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('interpret', 'VB', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('manipulate', 'VB', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('comprehend', 'VBP', 'O'),\n",
       " ('human', 'JJ', 'O'),\n",
       " ('language', 'NN', 'O'),\n",
       " ('.', '.', 'O'),\n",
       " ('Organizations', 'NNS', 'O'),\n",
       " ('today', 'NN', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('large', 'JJ', 'O'),\n",
       " ('volumes', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('voice', 'NN', 'O'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('text', 'NN', 'O'),\n",
       " ('data', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('various', 'JJ', 'O'),\n",
       " ('communication', 'NN', 'O'),\n",
       " ('channels', 'NNS', 'O'),\n",
       " ('like', 'IN', 'O'),\n",
       " ('emails', 'NNS', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('text', 'NN', 'O'),\n",
       " ('messages', 'NNS', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('social', 'JJ', 'O'),\n",
       " ('media', 'NNS', 'O'),\n",
       " ('newsfeeds', 'NNS', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('video', 'NN', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('audio', 'NN', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('more', 'JJR', 'O'),\n",
       " ('.', '.', 'O'),\n",
       " ('They', 'PRP', 'O'),\n",
       " ('use', 'VBP', 'O'),\n",
       " ('NLP', 'NNP', 'B-NE'),\n",
       " ('software', 'NN', 'O'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('automatically', 'RB', 'O'),\n",
       " ('process', 'VB', 'O'),\n",
       " ('this', 'DT', 'O'),\n",
       " ('data', 'NN', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('analyze', 'IN', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('intent', 'NN', 'O'),\n",
       " ('or', 'CC', 'O'),\n",
       " ('sentiment', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('message', 'NN', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('respond', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('real', 'JJ', 'O'),\n",
       " ('time', 'NN', 'O'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('human', 'VB', 'O'),\n",
       " ('communication.There', 'EX', 'O'),\n",
       " ('are', 'VBP', 'O'),\n",
       " ('470', 'CD', 'O'),\n",
       " ('illegal', 'JJ', 'O'),\n",
       " ('structures', 'NNS', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('including', 'VBG', 'O'),\n",
       " ('restaurants', 'NNS', 'O'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('cafes', 'NN', 'O'),\n",
       " (',', ',', 'O')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.chunk import tree2conlltags\n",
    "iob = tree2conlltags(ne)\n",
    "iob\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
